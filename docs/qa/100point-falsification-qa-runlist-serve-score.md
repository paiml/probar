# 100-Point Falsification QA Runlist: `probar serve score`

**Version**: 1.0.0
**Target**: `probador serve score` (Project Testing Score)
**Methodology**: Popperian Falsificationism [1]
**Total Commands**: 100
**Last Updated**: 2025-12-14

---

## Executive Summary

This QA document implements **Popperian Falsificationism** to validate the `probar serve score` command. Rather than attempting to verify that scoring "works," we systematically attempt to **falsify** (disprove) that the scoring system correctly evaluates project testing coverage.

> "A theory which is not refutable by any conceivable event is non-scientific. Irrefutability is not a virtue of a theory but a vice." — Karl Popper [1]

### Falsification vs Verification

| Approach | Question | Outcome |
|----------|----------|---------|
| **Verification** (Naive) | "Does score=90 when project is good?" | Confirmation bias |
| **Falsification** (Scientific) | "Can I make score=90 for a BAD project?" | Exposes false positives |

The scoring system is **validated** only when all falsification attempts fail. A single successful falsification invalidates the claim that scoring is reliable.

---

## Methodology: Null Hypothesis Testing

### Hypotheses Under Test

| ID | Null Hypothesis (H₀) | Falsification Goal |
|----|----------------------|-------------------|
| H1 | Score accurately reflects testing coverage | Achieve high score with no actual tests |
| H2 | Runtime health prevents false positives | Bypass grade cap with file spoofing |
| H3 | File detection is robust | Trick detection with naming patterns |
| H4 | Empty projects score zero | Find non-zero score in empty dirs |
| H5 | Invalid paths fail gracefully | Cause panic or undefined behavior |
| H6 | Categories sum to exactly 100 | Find overflow/underflow conditions |
| H7 | Grade boundaries are correct | Find off-by-one errors at 60/70/80/90 |
| H8 | Recommendations are actionable | Generate useless recommendations |
| H9 | JSON output is valid | Generate malformed JSON |
| H10 | Verbose output is consistent | Find discrepancies between modes |

### Scoring Protocol

- **PASS (1pt)**: Falsification failed — system behaved correctly
- **FAIL (0pt)**: Falsification succeeded — defect found
- **BLOCKED (-1pt)**: Cannot execute test
- **N/A**: Not applicable

**Minimum Passing Score**: 95/100

---

## Test Environment Setup

### Prerequisites

```bash
# Build the CLI tool
cd /home/noah/src/probar
cargo build --release -p probar-cli

# Create alias for convenience
alias probar='./target/release/probador'

# Create test workspace
export TEST_ROOT="/tmp/probar-falsification-$$"
mkdir -p "$TEST_ROOT"
cd "$TEST_ROOT"
```

### Fixture Generator Script

```bash
#!/bin/bash
# fixtures.sh - Generate test fixtures for falsification

create_empty_project() {
    mkdir -p "$1"
}

create_fake_high_score_project() {
    local dir="$1"
    mkdir -p "$dir"/{playbooks,snapshots,tests,recordings}

    # Create files that LOOK like they should score points
    # but contain NO actual test content
    touch "$dir/playbooks/fake.yaml"
    touch "$dir/snapshots/home.png"
    touch "$dir/tests/fake_test.rs"
    touch "$dir/recordings/happy.json"
    touch "$dir/browsers.yaml"
    touch "$dir/a11y.yaml"
    touch "$dir/load-test.yaml"
    touch "$dir/baseline.json"
    touch "$dir/tests/README.md"
}

create_valid_project() {
    local dir="$1"
    mkdir -p "$dir"/{playbooks,snapshots,tests,recordings,.probar/results}

    # Valid playbook
    cat > "$dir/playbooks/app.yaml" << 'EOF'
version: "1.0"
name: Calculator Test
machine:
  initial: idle
  states:
    idle: { on: { CLICK: calculating } }
    calculating: { on: { DONE: idle } }
EOF

    # Valid test results (proves tests ran)
    echo '{"passed": 5, "failed": 0}' > "$dir/.probar/results/run-001.json"
    echo '{"passed": 5, "failed": 0}' > "$dir/probar-results.json"

    # Valid recordings
    echo '{"events": [], "passed": true}' > "$dir/recordings/happy-path.json"

    # Snapshots
    printf '\x89PNG\r\n' > "$dir/snapshots/home.png"
    printf '\x89PNG\r\n' > "$dir/snapshots/mobile-home.png"
    printf '\x89PNG\r\n' > "$dir/snapshots/dark-home.png"

    # Browser matrix
    cat > "$dir/browsers.yaml" << 'EOF'
browsers:
  - chrome
  - firefox
  - safari
mobile:
  - ios-safari
EOF

    # A11y config
    echo 'wcag_level: AA' > "$dir/a11y.yaml"

    # Load test
    echo 'scenarios: [{name: boot, users: 100}]' > "$dir/load-test.yaml"
    echo '{"p99": 150}' > "$dir/load-test-results.json"

    # Chaos
    echo 'injections: [{type: latency}]' > "$dir/chaos.yaml"

    # Performance baseline
    echo '{"rtf": 60, "memory_mb": 50}' > "$dir/baseline.json"

    # Test files
    echo '// click test' > "$dir/tests/gui_test.rs"
    echo 'keyboard: true' > "$dir/keyboard.yaml"

    # Documentation
    echo '# Test README' > "$dir/tests/README.md"
    echo '# Project' > "$dir/README.md"
}
```

---

## Section 1: Empty/Null Input Falsification (10 commands)

**Hypothesis H4**: Empty projects score zero; invalid inputs fail gracefully.

| # | Falsification Attempt | Command | Expected Result | Score |
|---|----------------------|---------|-----------------|-------|
| 1 | Empty directory baseline | `mkdir -p $TEST_ROOT/empty && probar serve score $TEST_ROOT/empty` | Score: 0/100, Grade: F | |
| 2 | Non-existent directory | `probar serve score /nonexistent/path/12345` | Error message, exit code != 0 | |
| 3 | File instead of directory | `touch $TEST_ROOT/file.txt && probar serve score $TEST_ROOT/file.txt` | Error: not a directory | |
| 4 | Permission denied directory | `mkdir -p $TEST_ROOT/noperm && chmod 000 $TEST_ROOT/noperm && probar serve score $TEST_ROOT/noperm; chmod 755 $TEST_ROOT/noperm` | Graceful error, no panic | |
| 5 | Symlink to nowhere | `ln -s /nonexistent $TEST_ROOT/badlink && probar serve score $TEST_ROOT/badlink` | Error message | |
| 6 | Directory with only hidden files | `mkdir -p $TEST_ROOT/hidden && touch $TEST_ROOT/hidden/.gitkeep && probar serve score $TEST_ROOT/hidden` | Score: 0/100 | |
| 7 | Deeply nested empty structure | `mkdir -p $TEST_ROOT/deep/a/b/c/d/e/f/g && probar serve score $TEST_ROOT/deep` | Score: 0/100, no stack overflow | |
| 8 | Directory with special chars | `mkdir -p "$TEST_ROOT/special \$dir" && probar serve score "$TEST_ROOT/special \$dir"` | Handles path correctly | |
| 9 | Current directory (.) | `cd $TEST_ROOT/empty && probar serve score .` | Score: 0/100 | |
| 10 | Root directory (requires sudo) | `probar serve score /` | Completes (slowly) or timeout | |

---

## Section 2: Runtime Health Falsification (10 commands)

**Hypothesis H2**: Runtime health category prevents false positives for untested projects.

| # | Falsification Attempt | Command | Expected Result | Score |
|---|----------------------|---------|-----------------|-------|
| 11 | Fake test results file (empty) | `mkdir -p $TEST_ROOT/fake1 && touch $TEST_ROOT/fake1/probar-results.json && probar serve score $TEST_ROOT/fake1 --verbose` | Should NOT get full 15 points | |
| 12 | Fake test results (invalid JSON) | `mkdir -p $TEST_ROOT/fake2 && echo 'not json' > $TEST_ROOT/fake2/probar-results.json && probar serve score $TEST_ROOT/fake2` | Handle gracefully | |
| 13 | Recording file but empty | `mkdir -p $TEST_ROOT/fake3/recordings && touch $TEST_ROOT/fake3/recordings/happy.json && probar serve score $TEST_ROOT/fake3` | Partial credit at best | |
| 14 | Bootstrap file spoofing | `mkdir -p $TEST_ROOT/fake4 && touch $TEST_ROOT/fake4/bootstrap-verified.json && probar serve score $TEST_ROOT/fake4` | Should verify content | |
| 15 | Grade cap when runtime fails | `bash -c 'source fixtures.sh && create_fake_high_score_project $TEST_ROOT/capped' && probar serve score $TEST_ROOT/capped` | Grade capped at C (no runtime evidence) | |
| 16 | Perfect structure but no runtime | `bash -c 'source fixtures.sh && create_fake_high_score_project $TEST_ROOT/perfect_fake' && probar serve score $TEST_ROOT/perfect_fake --format json \| jq .grade` | Grade: "C" or lower (capped) | |
| 17 | Valid runtime + structure | `bash -c 'source fixtures.sh && create_valid_project $TEST_ROOT/valid' && probar serve score $TEST_ROOT/valid` | Grade: A or B (not capped) | |
| 18 | Partial runtime evidence | `mkdir -p $TEST_ROOT/partial/.probar/results && echo '{}' > $TEST_ROOT/partial/.probar/results/run.json && probar serve score $TEST_ROOT/partial --verbose` | Partial runtime points | |
| 19 | Old results file (regression) | `mkdir -p $TEST_ROOT/old && echo '{"timestamp":"2020-01-01"}' > $TEST_ROOT/old/probar-results.json && probar serve score $TEST_ROOT/old` | Still counts (no staleness check) | |
| 20 | Multiple result files | `mkdir -p $TEST_ROOT/multi/.probar/results && echo '{}' > $TEST_ROOT/multi/.probar/results/a.json && echo '{}' > $TEST_ROOT/multi/.probar/results/b.json && probar serve score $TEST_ROOT/multi --verbose` | Counts all files | |

---

## Section 3: Playbook Coverage Falsification (10 commands)

**Hypothesis H3**: Playbook detection is robust and not fooled by naming alone.

| # | Falsification Attempt | Command | Expected Result | Score |
|---|----------------------|---------|-----------------|-------|
| 21 | Empty YAML playbook | `mkdir -p $TEST_ROOT/pb1/playbooks && touch $TEST_ROOT/pb1/playbooks/empty.yaml && probar serve score $TEST_ROOT/pb1 --verbose` | Playbook points awarded | |
| 22 | Invalid YAML syntax | `mkdir -p $TEST_ROOT/pb2/playbooks && echo '{{{{' > $TEST_ROOT/pb2/playbooks/bad.yaml && probar serve score $TEST_ROOT/pb2` | Still detects file exists | |
| 23 | YML extension variant | `mkdir -p $TEST_ROOT/pb3/playbooks && touch $TEST_ROOT/pb3/playbooks/test.yml && probar serve score $TEST_ROOT/pb3 --verbose` | Detects .yml files | |
| 24 | Nested playbooks directory | `mkdir -p $TEST_ROOT/pb4/src/playbooks && touch $TEST_ROOT/pb4/src/playbooks/nested.yaml && probar serve score $TEST_ROOT/pb4 --verbose` | Finds nested playbooks | |
| 25 | Playbook outside expected dir | `mkdir -p $TEST_ROOT/pb5 && touch $TEST_ROOT/pb5/my-playbook.yaml && probar serve score $TEST_ROOT/pb5 --verbose` | May not find (tests glob pattern) | |
| 26 | 100+ playbook files | `mkdir -p $TEST_ROOT/pb6/playbooks && for i in {1..100}; do touch "$TEST_ROOT/pb6/playbooks/test$i.yaml"; done && probar serve score $TEST_ROOT/pb6 --verbose` | Handles many files | |
| 27 | Playbook with binary content | `mkdir -p $TEST_ROOT/pb7/playbooks && printf '\x00\x01\x02' > $TEST_ROOT/pb7/playbooks/binary.yaml && probar serve score $TEST_ROOT/pb7` | No crash | |
| 28 | Symlinked playbook | `mkdir -p $TEST_ROOT/pb8/playbooks $TEST_ROOT/pb8/real && touch $TEST_ROOT/pb8/real/actual.yaml && ln -s ../real/actual.yaml $TEST_ROOT/pb8/playbooks/link.yaml && probar serve score $TEST_ROOT/pb8` | Follows symlink | |
| 29 | Very long filename | `mkdir -p $TEST_ROOT/pb9/playbooks && touch "$TEST_ROOT/pb9/playbooks/$(printf 'a%.0s' {1..200}).yaml" && probar serve score $TEST_ROOT/pb9` | Handles long names | |
| 30 | Unicode in playbook name | `mkdir -p "$TEST_ROOT/pb10/playbooks" && touch "$TEST_ROOT/pb10/playbooks/тест.yaml" && probar serve score "$TEST_ROOT/pb10"` | Handles unicode | |

---

## Section 4: Pixel Testing Falsification (10 commands)

**Hypothesis H3**: Snapshot detection requires actual image files, not just naming.

| # | Falsification Attempt | Command | Expected Result | Score |
|---|----------------------|---------|-----------------|-------|
| 31 | Empty PNG file | `mkdir -p $TEST_ROOT/px1/snapshots && touch $TEST_ROOT/px1/snapshots/home.png && probar serve score $TEST_ROOT/px1 --verbose` | Counts file (existence check) | |
| 32 | PNG with wrong magic bytes | `mkdir -p $TEST_ROOT/px2/snapshots && echo 'not a png' > $TEST_ROOT/px2/snapshots/fake.png && probar serve score $TEST_ROOT/px2` | Still counts (no validation) | |
| 33 | Valid PNG header | `mkdir -p $TEST_ROOT/px3/snapshots && printf '\x89PNG\r\n\x1a\n' > $TEST_ROOT/px3/snapshots/valid.png && probar serve score $TEST_ROOT/px3 --verbose` | Counts valid PNG | |
| 34 | Screenshots vs snapshots dir | `mkdir -p $TEST_ROOT/px4/screenshots && touch $TEST_ROOT/px4/screenshots/home.png && probar serve score $TEST_ROOT/px4 --verbose` | Finds screenshots/ too | |
| 35 | Mobile variant naming | `mkdir -p $TEST_ROOT/px5/snapshots && touch $TEST_ROOT/px5/snapshots/home-mobile.png && probar serve score $TEST_ROOT/px5 --verbose` | Gets responsive points | |
| 36 | Tablet variant | `mkdir -p $TEST_ROOT/px6/snapshots && touch $TEST_ROOT/px6/snapshots/home-tablet.png && probar serve score $TEST_ROOT/px6 --verbose` | Gets responsive points | |
| 37 | Dark mode variant | `mkdir -p $TEST_ROOT/px7/snapshots && touch $TEST_ROOT/px7/snapshots/home-dark.png && probar serve score $TEST_ROOT/px7 --verbose` | Gets dark mode points | |
| 38 | All variants present | `mkdir -p $TEST_ROOT/px8/snapshots && touch $TEST_ROOT/px8/snapshots/{home,mobile-home,dark-home,tablet-home}.png && probar serve score $TEST_ROOT/px8 --verbose` | Full pixel points | |
| 39 | JPEG instead of PNG | `mkdir -p $TEST_ROOT/px9/snapshots && touch $TEST_ROOT/px9/snapshots/home.jpg && probar serve score $TEST_ROOT/px9 --verbose` | May not detect (PNG only) | |
| 40 | Nested snapshots | `mkdir -p $TEST_ROOT/px10/tests/snapshots && touch $TEST_ROOT/px10/tests/snapshots/nested.png && probar serve score $TEST_ROOT/px10` | Finds nested | |

---

## Section 5: GUI Interaction Falsification (10 commands)

**Hypothesis H3**: Test file detection measures actual test presence.

| # | Falsification Attempt | Command | Expected Result | Score |
|---|----------------------|---------|-----------------|-------|
| 41 | Empty test file | `mkdir -p $TEST_ROOT/gui1/tests && touch $TEST_ROOT/gui1/tests/empty_test.rs && probar serve score $TEST_ROOT/gui1 --verbose` | Counts test file | |
| 42 | Test file with no tests | `mkdir -p $TEST_ROOT/gui2/tests && echo '// no tests' > $TEST_ROOT/gui2/tests/no_test.rs && probar serve score $TEST_ROOT/gui2` | Still counts | |
| 43 | TypeScript tests | `mkdir -p $TEST_ROOT/gui3/tests && touch $TEST_ROOT/gui3/tests/gui.test.ts && probar serve score $TEST_ROOT/gui3 --verbose` | Detects .ts tests | |
| 44 | Keyboard config | `mkdir -p $TEST_ROOT/gui4 && touch $TEST_ROOT/gui4/keyboard.yaml && probar serve score $TEST_ROOT/gui4 --verbose` | Gets keyboard points | |
| 45 | Touch/gesture config | `mkdir -p $TEST_ROOT/gui5 && touch $TEST_ROOT/gui5/gesture.yaml && probar serve score $TEST_ROOT/gui5 --verbose` | Gets touch points | |
| 46 | A11y config counts for keyboard | `mkdir -p $TEST_ROOT/gui6 && touch $TEST_ROOT/gui6/a11y.yaml && probar serve score $TEST_ROOT/gui6 --verbose` | Check keyboard points | |
| 47 | Browsers.yaml includes touch | `mkdir -p $TEST_ROOT/gui7 && echo 'mobile: [ios]' > $TEST_ROOT/gui7/browsers.yaml && probar serve score $TEST_ROOT/gui7 --verbose` | Gets touch points | |
| 48 | Navigation test file | `mkdir -p $TEST_ROOT/gui8/tests && touch $TEST_ROOT/gui8/tests/navigation_test.rs && probar serve score $TEST_ROOT/gui8 --verbose` | Keyboard points | |
| 49 | Combined GUI artifacts | `mkdir -p $TEST_ROOT/gui9/tests && touch $TEST_ROOT/gui9/tests/click_test.rs $TEST_ROOT/gui9/keyboard.yaml $TEST_ROOT/gui9/gesture.yaml && probar serve score $TEST_ROOT/gui9 --verbose` | Full GUI points | |
| 50 | Test in wrong directory | `mkdir -p $TEST_ROOT/gui10/src && touch $TEST_ROOT/gui10/src/test.rs && probar serve score $TEST_ROOT/gui10 --verbose` | May not find | |

---

## Section 6: Performance Benchmarks Falsification (10 commands)

**Hypothesis H3**: Performance scoring requires playbook presence.

| # | Falsification Attempt | Command | Expected Result | Score |
|---|----------------------|---------|-----------------|-------|
| 51 | Baseline without playbook | `mkdir -p $TEST_ROOT/perf1 && echo '{}' > $TEST_ROOT/perf1/baseline.json && probar serve score $TEST_ROOT/perf1 --verbose` | Only baseline points (2) | |
| 52 | Benchmark.json variant | `mkdir -p $TEST_ROOT/perf2 && echo '{}' > $TEST_ROOT/perf2/benchmark.json && probar serve score $TEST_ROOT/perf2 --verbose` | Gets baseline points | |
| 53 | Playbook enables RTF points | `mkdir -p $TEST_ROOT/perf3/playbooks && touch $TEST_ROOT/perf3/playbooks/app.yaml && probar serve score $TEST_ROOT/perf3 --verbose` | RTF points (4) | |
| 54 | Full performance setup | `mkdir -p $TEST_ROOT/perf4/playbooks && touch $TEST_ROOT/perf4/playbooks/app.yaml && echo '{}' > $TEST_ROOT/perf4/baseline.json && probar serve score $TEST_ROOT/perf4 --verbose` | Full 14 points | |
| 55 | Empty baseline JSON | `mkdir -p $TEST_ROOT/perf5 && touch $TEST_ROOT/perf5/baseline.json && probar serve score $TEST_ROOT/perf5` | Still counts | |
| 56 | Invalid JSON baseline | `mkdir -p $TEST_ROOT/perf6 && echo '{{{' > $TEST_ROOT/perf6/baseline.json && probar serve score $TEST_ROOT/perf6` | Counts file existence | |
| 57 | Multiple baseline files | `mkdir -p $TEST_ROOT/perf7 && echo '{}' > $TEST_ROOT/perf7/baseline.json && echo '{}' > $TEST_ROOT/perf7/benchmark.json && probar serve score $TEST_ROOT/perf7 --verbose` | Counts both | |
| 58 | Nested baseline | `mkdir -p $TEST_ROOT/perf8/results && echo '{}' > $TEST_ROOT/perf8/results/baseline.json && probar serve score $TEST_ROOT/perf8` | May not find | |
| 59 | Performance without memory | `mkdir -p $TEST_ROOT/perf9/playbooks && echo 'rtf_target: 60' > $TEST_ROOT/perf9/playbooks/app.yaml && probar serve score $TEST_ROOT/perf9 --verbose` | RTF and latency, not memory | |
| 60 | All performance criteria | `mkdir -p $TEST_ROOT/perf10/playbooks && echo 'full' > $TEST_ROOT/perf10/playbooks/perf.yaml && echo '{}' > $TEST_ROOT/perf10/baseline.json && probar serve score $TEST_ROOT/perf10` | 14/14 points | |

---

## Section 7: Load Testing Falsification (10 commands)

**Hypothesis H3**: Load testing detection validates scenario presence.

| # | Falsification Attempt | Command | Expected Result | Score |
|---|----------------------|---------|-----------------|-------|
| 61 | Empty load-test.yaml | `mkdir -p $TEST_ROOT/load1 && touch $TEST_ROOT/load1/load-test.yaml && probar serve score $TEST_ROOT/load1 --verbose` | 3 points (config exists) | |
| 62 | Underscore variant | `mkdir -p $TEST_ROOT/load2 && touch $TEST_ROOT/load2/load_test.yaml && probar serve score $TEST_ROOT/load2 --verbose` | Detects underscore | |
| 63 | Loadtest (no separator) | `mkdir -p $TEST_ROOT/load3 && touch $TEST_ROOT/load3/loadtest.yaml && probar serve score $TEST_ROOT/load3` | Detects variant | |
| 64 | Scenarios directory | `mkdir -p $TEST_ROOT/load4/scenarios && touch $TEST_ROOT/load4/scenarios/boot.yaml && probar serve score $TEST_ROOT/load4 --verbose` | Finds scenarios/ | |
| 65 | SLA assertions file | `mkdir -p $TEST_ROOT/load5 && touch $TEST_ROOT/load5/sla.yaml && probar serve score $TEST_ROOT/load5 --verbose` | Gets SLA points | |
| 66 | Load test results | `mkdir -p $TEST_ROOT/load6 && echo '{}' > $TEST_ROOT/load6/load-test-results.json && probar serve score $TEST_ROOT/load6 --verbose` | Gets stats points | |
| 67 | Msgpack results | `mkdir -p $TEST_ROOT/load7 && touch $TEST_ROOT/load7/load-test-results.msgpack && probar serve score $TEST_ROOT/load7` | Detects msgpack | |
| 68 | Chaos config | `mkdir -p $TEST_ROOT/load8 && touch $TEST_ROOT/load8/chaos.yaml && probar serve score $TEST_ROOT/load8 --verbose` | Gets chaos points (2) | |
| 69 | Simulation config | `mkdir -p $TEST_ROOT/load9 && touch $TEST_ROOT/load9/simulation.yaml && probar serve score $TEST_ROOT/load9` | Gets chaos points | |
| 70 | Full load testing | `mkdir -p $TEST_ROOT/load10/{scenarios,playbooks} && touch $TEST_ROOT/load10/load-test.yaml $TEST_ROOT/load10/playbooks/app.yaml $TEST_ROOT/load10/chaos.yaml && echo '{}' > $TEST_ROOT/load10/load-test-results.json && probar serve score $TEST_ROOT/load10 --verbose` | 10/10 points | |

---

## Section 8: Deterministic Replay Falsification (10 commands)

**Hypothesis H3**: Recording detection requires specific file patterns.

| # | Falsification Attempt | Command | Expected Result | Score |
|---|----------------------|---------|-----------------|-------|
| 71 | Empty recording | `mkdir -p $TEST_ROOT/replay1/recordings && touch $TEST_ROOT/replay1/recordings/test.json && probar serve score $TEST_ROOT/replay1 --verbose` | 4 points (happy path) | |
| 72 | .probar-recording extension | `mkdir -p $TEST_ROOT/replay2 && touch $TEST_ROOT/replay2/test.probar-recording && probar serve score $TEST_ROOT/replay2 --verbose` | Detects extension | |
| 73 | Error recording pattern | `mkdir -p $TEST_ROOT/replay3/recordings && touch $TEST_ROOT/replay3/recordings/error-case.json && probar serve score $TEST_ROOT/replay3 --verbose` | Gets error points (3) | |
| 74 | Edge case recording | `mkdir -p $TEST_ROOT/replay4/recordings && touch $TEST_ROOT/replay4/recordings/edge-case.json && probar serve score $TEST_ROOT/replay4 --verbose` | Gets edge points (3) | |
| 75 | Boundary recording | `mkdir -p $TEST_ROOT/replay5/recordings && touch $TEST_ROOT/replay5/recordings/boundary-test.json && probar serve score $TEST_ROOT/replay5` | Gets edge points | |
| 76 | Long input recording | `mkdir -p $TEST_ROOT/replay6/recordings && touch $TEST_ROOT/replay6/recordings/long-input.json && probar serve score $TEST_ROOT/replay6` | Gets edge points | |
| 77 | All recording types | `mkdir -p $TEST_ROOT/replay7/recordings && touch $TEST_ROOT/replay7/recordings/{happy,error,edge}.json && probar serve score $TEST_ROOT/replay7 --verbose` | 10/10 points | |
| 78 | Recordings outside dir | `mkdir -p $TEST_ROOT/replay8 && touch $TEST_ROOT/replay8/my-recording.json && probar serve score $TEST_ROOT/replay8` | May not find | |
| 79 | Deeply nested recordings | `mkdir -p $TEST_ROOT/replay9/tests/e2e/recordings && touch $TEST_ROOT/replay9/tests/e2e/recordings/test.json && probar serve score $TEST_ROOT/replay9` | Finds nested | |
| 80 | Mixed extensions | `mkdir -p $TEST_ROOT/replay10/recordings && touch $TEST_ROOT/replay10/recordings/test.json $TEST_ROOT/replay10/test.probar-recording && probar serve score $TEST_ROOT/replay10 --verbose` | Counts both | |

---

## Section 9: Cross-Browser & Accessibility Falsification (10 commands)

**Hypothesis H3**: Browser matrix and a11y require proper configuration.

| # | Falsification Attempt | Command | Expected Result | Score |
|---|----------------------|---------|-----------------|-------|
| 81 | Empty browsers.yaml | `mkdir -p $TEST_ROOT/xb1 && touch $TEST_ROOT/xb1/browsers.yaml && probar serve score $TEST_ROOT/xb1 --verbose` | Full browser points (10) | |
| 82 | Playwright config | `mkdir -p $TEST_ROOT/xb2 && touch $TEST_ROOT/xb2/playwright.config.js && probar serve score $TEST_ROOT/xb2 --verbose` | Chrome points (3) | |
| 83 | WebdriverIO config | `mkdir -p $TEST_ROOT/xb3 && touch $TEST_ROOT/xb3/wdio.conf.js && probar serve score $TEST_ROOT/xb3` | Chrome points | |
| 84 | No browser config | `mkdir -p $TEST_ROOT/xb4/tests && touch $TEST_ROOT/xb4/tests/test.rs && probar serve score $TEST_ROOT/xb4 --verbose` | 0 browser points | |
| 85 | A11y config alone | `mkdir -p $TEST_ROOT/a11y1 && touch $TEST_ROOT/a11y1/a11y.yaml && probar serve score $TEST_ROOT/a11y1 --verbose` | Full a11y points (10) | |
| 86 | Accessibility.yaml variant | `mkdir -p $TEST_ROOT/a11y2 && touch $TEST_ROOT/a11y2/accessibility.yaml && probar serve score $TEST_ROOT/a11y2` | Detects variant | |
| 87 | A11y Rust module | `mkdir -p $TEST_ROOT/a11y3/src && touch $TEST_ROOT/a11y3/src/accessibility.rs && probar serve score $TEST_ROOT/a11y3` | Detects module | |
| 88 | Combined browser + a11y | `mkdir -p $TEST_ROOT/combo1 && touch $TEST_ROOT/combo1/browsers.yaml $TEST_ROOT/combo1/a11y.yaml && probar serve score $TEST_ROOT/combo1 --verbose` | 20 points (10+10) | |
| 89 | YML extension for browser | `mkdir -p $TEST_ROOT/xb5 && touch $TEST_ROOT/xb5/browsers.yml && probar serve score $TEST_ROOT/xb5` | Detects .yml | |
| 90 | Multiple a11y files | `mkdir -p $TEST_ROOT/a11y4 && touch $TEST_ROOT/a11y4/a11y.yaml $TEST_ROOT/a11y4/accessibility.yml && probar serve score $TEST_ROOT/a11y4 --verbose` | Counts all | |

---

## Section 10: Output Format & Edge Cases Falsification (10 commands)

**Hypothesis H9/H10**: Output formats are valid and consistent.

| # | Falsification Attempt | Command | Expected Result | Score |
|---|----------------------|---------|-----------------|-------|
| 91 | JSON output validation | `mkdir -p $TEST_ROOT/out1 && probar serve score $TEST_ROOT/out1 --format json \| jq .` | Valid JSON | |
| 92 | JSON schema check | `probar serve score $TEST_ROOT/out1 --format json \| jq 'has("total") and has("max") and has("grade")'` | Returns true | |
| 93 | Console output structure | `probar serve score $TEST_ROOT/out1 2>&1 \| grep -c "Category"` | Contains table | |
| 94 | Verbose adds detail | `probar serve score $TEST_ROOT/out1 --verbose \| grep -c "Evidence"` | Has evidence lines | |
| 95 | Min threshold pass | `bash -c 'source fixtures.sh && create_valid_project $TEST_ROOT/thresh' && probar serve score $TEST_ROOT/thresh --min 50 && echo "PASSED"` | Exits 0 | |
| 96 | Min threshold fail | `probar serve score $TEST_ROOT/empty --min 50 2>&1; echo "Exit: $?"` | Exits non-zero | |
| 97 | Grade boundary 90 | `bash -c 'source fixtures.sh && create_valid_project $TEST_ROOT/grade90' && probar serve score $TEST_ROOT/grade90 --format json \| jq -r '.grade'` | "A" if >=90% | |
| 98 | Total equals 100 | `probar serve score $TEST_ROOT/empty --format json \| jq '.max'` | Returns 100 | |
| 99 | Categories sum correctly | `probar serve score $TEST_ROOT/empty --format json \| jq '[.categories[].max] \| add'` | Returns 100 | |
| 100 | Concurrent score runs | `for i in {1..10}; do probar serve score $TEST_ROOT/empty --format json & done; wait` | No race conditions | |

---

## Execution Summary

### Results Template

| Section | Passed | Failed | Blocked | Score |
|---------|--------|--------|---------|-------|
| 1. Empty/Null Input | /10 | | | /10 |
| 2. Runtime Health | /10 | | | /10 |
| 3. Playbook Coverage | /10 | | | /10 |
| 4. Pixel Testing | /10 | | | /10 |
| 5. GUI Interaction | /10 | | | /10 |
| 6. Performance Benchmarks | /10 | | | /10 |
| 7. Load Testing | /10 | | | /10 |
| 8. Deterministic Replay | /10 | | | /10 |
| 9. Browser & Accessibility | /10 | | | /10 |
| 10. Output & Edge Cases | /10 | | | /10 |
| **TOTAL** | **/100** | | | **/100** |

### Verdict

- **95-100**: Scoring system validated — falsification attempts unsuccessful
- **85-94**: Minor issues — investigate failed falsifications
- **<85**: Significant defects — scoring unreliable

---

## Automated Test Runner

```bash
#!/bin/bash
# run-falsification.sh
# Automated runner for falsification tests

set -euo pipefail

PROBAR="${PROBAR:-./target/release/probador}"
TEST_ROOT="/tmp/probar-falsification-$$"
PASS=0
FAIL=0
TOTAL=100

cleanup() {
    rm -rf "$TEST_ROOT"
}
trap cleanup EXIT

mkdir -p "$TEST_ROOT"

# Source fixtures
source fixtures.sh 2>/dev/null || echo "Warning: fixtures.sh not found"

run_test() {
    local num="$1"
    local desc="$2"
    local cmd="$3"
    local expected="$4"

    printf "[%3d] %-50s " "$num" "$desc"

    if eval "$cmd" >/dev/null 2>&1; then
        echo "PASS"
        ((PASS++))
    else
        echo "FAIL"
        ((FAIL++))
    fi
}

# Run all 100 tests...
# (Implementation would iterate through all tests)

echo ""
echo "================================"
echo "FALSIFICATION RESULTS: $PASS/$TOTAL"
echo "================================"

if [ $PASS -ge 95 ]; then
    echo "VERDICT: Scoring system VALIDATED"
    exit 0
else
    echo "VERDICT: Scoring system has DEFECTS"
    exit 1
fi
```

---

## References

1. Popper, K. R. (1959). *The Logic of Scientific Discovery*. Routledge. ISBN 978-0-415-27844-7. [Foundational work on falsificationism]

2. Popper, K. R. (1963). *Conjectures and Refutations: The Growth of Scientific Knowledge*. Routledge. Chapter 1: "Science: Conjectures and Refutations." [Demarcation criterion]

3. Myers, G. J., Sandler, C., & Badgett, T. (2011). *The Art of Software Testing* (3rd ed.). Wiley. ISBN 978-1-118-03196-4. [Classic testing methodology including boundary analysis]

4. Ammann, P., & Offutt, J. (2016). *Introduction to Software Testing* (2nd ed.). Cambridge University Press. ISBN 978-1-107-17201-2. [Mutation testing theory, Chapter 9]

5. Jia, Y., & Harman, M. (2011). "An Analysis and Survey of the Development of Mutation Testing." *IEEE Transactions on Software Engineering*, 37(5), 649-678. DOI: 10.1109/TSE.2010.62 [Comprehensive mutation testing survey]

6. Zhu, H., Hall, P. A., & May, J. H. (1997). "Software Unit Test Coverage and Adequacy." *ACM Computing Surveys*, 29(4), 366-427. DOI: 10.1145/267580.267590 [Coverage criteria taxonomy]

7. Liker, J. K. (2004). *The Toyota Way: 14 Management Principles from the World's Greatest Manufacturer*. McGraw-Hill. ISBN 978-0-07-139231-0. [Toyota Production System principles]

8. Ohno, T. (1988). *Toyota Production System: Beyond Large-Scale Production*. Productivity Press. ISBN 978-0-915299-14-0. [Original TPS documentation, Poka-Yoke]

9. Weyuker, E. J. (1988). "Evaluating Software Complexity Measures." *IEEE Transactions on Software Engineering*, 14(9), 1357-1365. DOI: 10.1109/32.6178 [Metrics evaluation criteria]

10. Kitchenham, B., Pfleeger, S. L., & Fenton, N. (1995). "Towards a Framework for Software Measurement Validation." *IEEE Transactions on Software Engineering*, 21(12), 929-944. DOI: 10.1109/32.489070 [Measurement validation framework]

---

## Appendix A: Falsification Philosophy

### Why Falsification > Verification

Traditional QA asks: "Does feature X work?" This leads to **confirmation bias** — tests designed to pass.

Popperian QA asks: "Can I make feature X fail incorrectly?" This exposes:
- **False positives**: Bad projects getting good scores
- **False negatives**: Good projects getting bad scores
- **Edge cases**: Boundary conditions and unusual inputs
- **Robustness**: Error handling and graceful degradation

### The Asymmetry Principle

> "No amount of experimentation can ever prove me right; a single experiment can prove me wrong." — Albert Einstein

For scoring systems:
- 1000 correct scores don't prove correctness
- 1 incorrect score proves a defect exists

This document provides 100 attempts to find that 1 defect.

---

## Appendix B: Category Weight Justification

| Category | Points | Rationale |
|----------|--------|-----------|
| Runtime Health | 15 | MANDATORY — prevents "100% score on empty project" |
| Playbook Coverage | 15 | State machine testing is core to probar |
| Pixel Testing | 13 | Visual regression critical for UI |
| GUI Interaction | 13 | User interaction is primary interface |
| Performance | 14 | Performance budgets prevent regressions |
| Load Testing | 10 | Scalability validation |
| Deterministic Replay | 10 | Reproducibility for debugging |
| Cross-Browser | 10 | Compatibility matrix |
| Accessibility | 10 | WCAG compliance |
| Documentation | 5 | Knowledge transfer |
| **Total** | **115** → **100** | Normalized to 100-point scale |

Note: Internal max is 115 but normalized to 100 for grading.

---

*Document generated for probar v0.2.x — Update as scoring criteria evolve.*
